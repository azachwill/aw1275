<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.38">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2020-01-29">

<title>sparklyr 1.1: Foundations, Books, Lakes and Barriers</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
.display.math{display: block; text-align: center; margin: 0.5rem auto;}
</style>


<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">


</head>

<body>


<header id="title-block-header">
<h1 class="title">sparklyr 1.1: Foundations, Books, Lakes and Barriers</h1>

<p class="date">2020-01-29</p>
</header>

<p><img src="2020-01-29-sparklyr-1-1-linux-foundation-roadmap.png" style="display: none;" alt="Linux Foundation roadmap projects and sparklyr"></p>
<p>Today we are excited to share that <a href="https://github.com/sparklyr/sparklyr">sparklyr</a> <code>1.1</code> is now available on <a href="https://CRAN.R-project.org/package=sparklyr">CRAN</a>!</p>
<p>In a nutshell, you can use sparklyr to scale datasets across computing clusters running <a href="http://spark.apache.org">Apache Spark</a>. For this particular release, we would like to highlight the following new features:</p>
<ul>
<li><strong><a href="#delta-lake">Delta Lake</a></strong> enables database-like properties in Spark.</li>
<li><strong><a href="#spark-3-0">Spark 3.0</a></strong> preview is now available through sparklyr.</li>
<li><strong><a href="#barrier-execution">Barrier Execution</a></strong> paves the way to use Spark with deep learning frameworks.</li>
<li><strong><a href="#qubole">Qubole</a></strong> clusters running Spark can be easily used with sparklyr.</li>
</ul>
<p>In addition, new community <strong><a href="#extensions">Extensions</a></strong> enable natural language processing and genomics, sparklyr is now being hosted within the <strong><a href="#linux-foundation">Linux Foundation</a></strong>, and the <strong><a href="#mastering-spark-with-r">Mastering Spark with R</a></strong> book is now available and free-to-use online.</p>
<p>You can install <code>sparklyr 1.1</code> from CRAN as follows:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"sparklyr"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<h2 id="delta-lake" class="anchored">Delta Lake</h2>
<p>The <a href="https://delta.io/">Delta Lake</a> project is an open-source storage layer that brings <a href="https://en.wikipedia.org/wiki/ACID">ACID transactions</a> to Apache Spark. To use Delta Lake, first connect using the new <code>packages</code> parameter set to <code>"delta"</code>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sparklyr)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>sc <span class="ot">&lt;-</span> <span class="fu">spark_connect</span>(<span class="at">master =</span> <span class="st">"local"</span>, <span class="at">version =</span> <span class="st">"2.4"</span>, <span class="at">packages =</span> <span class="st">"delta"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>As a simple example, let’s write a small data frame to Delta using <code>spark_write_delta()</code>, overwrite it, and then read it back with <code>spark_read_delta()</code>:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sdf_len</span>(sc, <span class="dv">5</span>) <span class="sc">%&gt;%</span> <span class="fu">spark_write_delta</span>(<span class="at">path =</span> <span class="st">"delta-test"</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sdf_len</span>(sc, <span class="dv">3</span>) <span class="sc">%&gt;%</span> <span class="fu">spark_write_delta</span>(<span class="at">path =</span> <span class="st">"delta-test"</span>, <span class="at">mode =</span> <span class="st">"overwrite"</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_read_delta</span>(sc, <span class="st">"/tmp/delta-1"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code># Source: spark&lt;delta1&gt; [?? x 1]
     id
  &lt;int&gt;
1     1
2     2
3     3</code></pre>
<p>Now, since Delta is capable of tracking all versions of your data, you can easily time travel to retrieve the version that we overwrote:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_read_delta</span>(sc, <span class="st">"delta-test"</span>, <span class="at">version =</span> 0L)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code># Source: spark&lt;delta1&gt; [?? x 1]
     id
  &lt;int&gt;
1     1
2     2
3     3
4     4
5     5</code></pre>
<h2 id="spark-3.0" class="anchored">Spark 3.0</h2>
<p>To install and try out Spark 3.0 preview, simply run:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sparklyr)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_install</span>(<span class="st">"3.0.0-preview"</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>sc <span class="ot">&lt;-</span> <span class="fu">spark_connect</span>(<span class="at">master =</span> <span class="st">"local"</span>, <span class="at">version =</span> <span class="st">"3.0.0-preview"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can then preview upcoming features, like the ability to read binary files. To demonstrate this, we can use <a href="https://blog.rstudio.com/2019/09/09/pin-discover-and-share-resources/">pins</a> to download a 237MB subset of <a href="http://www.image-net.org/">ImageNet</a>, and then load them into Spark:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>tiny_imagenet <span class="ot">&lt;-</span> pins<span class="sc">::</span><span class="fu">pin</span>(<span class="st">"http://cs231n.stanford.edu/tiny-imagenet-200.zip"</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_read_source</span>(sc, <span class="fu">dirname</span>(tiny_imagenet[<span class="dv">1</span>]), <span class="at">source =</span> <span class="st">"binaryFile"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code># Source: spark&lt;images&gt; [?? x 4]
   path                       modificationTime    length content   
   &lt;chr&gt;                      &lt;dttm&gt;               &lt;dbl&gt; &lt;list&gt;    
 1 file:images/test_2009.JPEG 2020-01-08 20:36:41   3138 &lt; [3,138]&gt;
 2 file:images/test_8245.JPEG 2020-01-08 20:36:43   3066 &lt; [3,066]&gt;
 3 file:images/test_4186.JPEG 2020-01-08 20:36:42   2998 &lt; [2,998]&gt;
 4 file:images/test_403.JPEG  2020-01-08 20:36:39   2980 &lt; [2,980]&gt;
 5 file:images/test_8544.JPEG 2020-01-08 20:36:38   2958 &lt; [2,958]&gt;
 6 file:images/test_5814.JPEG 2020-01-08 20:36:38   2929 &lt; [2,929]&gt;
 7 file:images/test_1063.JPEG 2020-01-08 20:36:41   2920 &lt; [2,920]&gt;
 8 file:images/test_1942.JPEG 2020-01-08 20:36:39   2908 &lt; [2,908]&gt;
 9 file:images/test_5456.JPEG 2020-01-08 20:36:42   2906 &lt; [2,906]&gt;
10 file:images/test_5859.JPEG 2020-01-08 20:36:39   2896 &lt; [2,896]&gt;
# … with more rows</code></pre>
<p>Please notice that the <a href="https://spark.apache.org/news/spark-3.0.0-preview.html">Spark 3.0.0 preview</a> not a stable release in terms of either API or functionality.</p>
<h2 id="barrier-execution" class="anchored">Barrier Execution</h2>
<p>Barrier execution is a new feature introduced in <a href="https://spark.apache.org/releases/spark-release-2-4-0.html">Spark 2.4</a> which enables Deep Learning on Apache Spark by implementing an all-or-nothing scheduler into Apache Spark. This allows Spark to not only process analytic workflows, but also to use Spark as a high-performance computing cluster where other framework, like <a href="https://www.openmp.org/">OpenMP</a> or <a href="https://www.tensorflow.org/guide/distributed_training">TensorFlow Distributed</a>, can reuse cluster machines and have them directly communicate with each other for a given task.</p>
<p>In general, we don’t expect most users to use this feature directly; instead, this is a feature relevant to advanced users interested in creating extensions that support additional modeling frameworks. You can learn more about barrier execution in Reynold Xin’s <a href="https://vimeo.com/274267107">keynote</a>.</p>
<p>To use barrier execution from R, set the <code>barrier = TRUE</code> parameter in <code>spark_apply()</code> and then make use of a new parameter in the R closure to retrieve the network address of the additional nodes available for this task. A simple example follows:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sparklyr)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>sc <span class="ot">&lt;-</span> <span class="fu">spark_connect</span>(<span class="at">master =</span> <span class="st">"local"</span>, <span class="at">version =</span> <span class="st">"2.4"</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="fu">sdf_len</span>(sc, <span class="dv">1</span>, <span class="at">repartition =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">spark_apply</span>(<span class="sc">~</span> .y<span class="sc">$</span>address, <span class="at">barrier =</span> <span class="cn">TRUE</span>, <span class="at">columns =</span> <span class="fu">c</span>(<span class="at">address =</span> <span class="st">"character"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code># A tibble: 1 x 1
  address        
  &lt;chr&gt;          
1 localhost:50693</code></pre>
<h2 id="qubole" class="anchored">Qubole</h2>
<p><a href="https://www.qubole.com/product/data-platform/">Qubole</a> is a fully self-service multi-cloud data platform based on enterprise-grade data processing engines including Apache Spark.</p>
<p>If you are using Qubole clusters, you can now easily connect to a Spark through a new <code>"qubole"</code> connection method:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sparklyr)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>sc <span class="ot">&lt;-</span> <span class="fu">spark_connect</span>(<span class="at">method =</span> <span class="st">"qubole"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Once connected, you can use Spark and R as usual. To learn more, visit <a href="https://docs.qubole.com/en/latest/user-guide/engines/spark/rstudio_spark.html">RStudio for Running Distributed R Jobs</a>.</p>
<h2 id="extensions" class="anchored">Extensions</h2>
<p>The new <a href="https://github.com/r-spark">github.com/r-spark</a> repo contains new community extensions. To mention a few, <a href="https://CRAN.R-project.org/package=variantspark">variantspark</a> and <a href="https://CRAN.R-project.org/package=sparkhail">sparkhail</a> are two new extensions for genomic research, <a href="https://github.com/r-spark/sparknlp">sparknlp</a> adds support for natural language processing.</p>
<p>For those of you with background in genomics, you can use <code>sparkhail</code> by first installing this extension from CRAN. Followed by connecting to Spark, creating a Hail Context, and then loading a subset of the <a href="https://www.internationalgenome.org/data/">1000 Genomes</a> dataset using <a href="https://hail.is/">Hail</a>:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sparklyr)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sparkhail)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>sc <span class="ot">&lt;-</span> <span class="fu">spark_connect</span>(<span class="at">master =</span> <span class="st">"local"</span>, <span class="at">version =</span> <span class="st">"2.4"</span>, <span class="at">config =</span> <span class="fu">hail_config</span>())</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>hc <span class="ot">&lt;-</span> <span class="fu">hail_context</span>(sc)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>hail_data <span class="ot">&lt;-</span> pins<span class="sc">::</span><span class="fu">pin</span>(<span class="st">"https://github.com/r-spark/sparkhail/blob/master/inst/extdata/1kg.zip?raw=true"</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>hail_df <span class="ot">&lt;-</span> <span class="fu">hail_read_matrix</span>(hc, <span class="fu">file.path</span>(<span class="fu">dirname</span>(hail_data[<span class="dv">1</span>]), <span class="st">"1kg.mt"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hail_dataframe</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can then analyze it with packages like <code>dplyr</code>, <code>sparklyr.nested</code>, and <code>dbplot</code>:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sdf_separate_column</span>(hail_df, <span class="st">"alleles"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(alleles_1, alleles_2) <span class="sc">%&gt;%</span> </span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tally</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="sc">-</span>n)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code># Source:     spark&lt;?&gt; [?? x 3]
# Groups:     alleles_1
# Ordered by: -n
   alleles_1 alleles_2     n
   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;
 1 C         T          2436
 2 G         A          2387
 3 A         G          1944
 4 T         C          1879
 5 C         A           496
 6 G         T           480
 7 T         G           468
 8 A         C           454
 9 C         G           150
10 G         C           112
# … with more rows</code></pre>
<p>Notice that these frequencies come in pairs, C/T and G/A are actually the same mutation, just viewed from opposite strands. You can then create a histogram over the DP field, depth of the proband, as follows:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>sparklyr.nested<span class="sc">::</span><span class="fu">sdf_select</span>(hail_df, <span class="at">dp =</span> info.DP) <span class="sc">%&gt;%</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  dbplot<span class="sc">::</span><span class="fu">dbplot_histogram</span>(dp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="2020-01-29-sparklyr-1-1-hail-histogram-pd.png" alt="Apache Spark, Hail, R, and sparklyr histogram"></p>
<p>This code was adapted from Hail’s <a href="https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html">Genome Wide Association-Study</a>. You can learn more about this Hail community extensions from <a href="https://github.com/r-spark/sparkhail">r-spark/sparkhail</a>.</p>
<h2 id="linux-foundation" class="anchored">Linux Foundation</h2>
<p>The <a href="https://www.linuxfoundation.org">Linux Foundation</a> is home of projects such as <a href="https://www.linuxfoundation.org/projects/linux/">Linux</a>, <a href="https://kubernetes.io/">Kubernetes</a>, <a href="https://js.foundation/">Node.js</a> and umbrella foundations such as <a href="https://lfai.foundation/">LF AI</a>, <a href="https://www.lfedge.org/">LF Edge</a>, and <a href="https://www.lfnetworking.org/">LF Network</a>. We are very excited to have sparklyr be hosted as an incubation project within LF AI alongside <a href="https://www.acumos.org/">Acumos</a>, <a href="https://lfai.foundation/projects/angel-ml/">Angel</a>, <a href="https://lfai.foundation/projects/horovod/">Horovod</a>, <a href="https://pyro.ai/">Pyro</a>, <a href="https://onnx.ai/">ONNX</a> and several others.</p>
<p>Hosting sparklyr in LF AI within the Linux Foundation provides a neutral entity to hold the project assets and open governance. Furthermore, we believe hosting with LF AI will also help bring additional talent, ideas, and shared components from other Linux Foundation projects like <a href="https://delta.io">Delta Lake</a>, <a href="https://eng.uber.com/horovod/">Horovod</a>, <a href="https://onnx.ai">ONNX</a>, and so on into sparklyr as part of cross-project and cross-foundation collaboration.</p>
<p>This makes it a great time for you to join the sparklyr community, contribute, and help this project grow. You can learn more about this in <a href="https://sparklyr.org">sparklyr.org</a>.</p>
<h2 id="mastering-spark-with-r" class="anchored">Mastering Spark with R</h2>
<p><a href="https://therinspark.com">Mastering Spark with R</a> is a new book to help you learn and master Apache Spark with R from start to finish. It introduces data analysis with well-known tools like <a href="https://dplyr.tidyverse.org/">dplyr</a>, and covers everything else related to processing large-scale datasets, modeling, productionizing pipelines, using extensions, distributing R code, and processing real-time data – if you are not yet familiar with Spark, this is a great resource to get started!</p>
<p><a href="https://therinspark.com">&lt;img src=“2020-01-29-sparklyr-1-1-book-cover.jpg” width=“200px”” alt=“Mastering Spark with R book cover”/&gt;</a></p>
<p>This book was published by <a href="http://shop.oreilly.com/product/0636920223764.do">O’Reilly</a>, is available on <a href="https://www.amazon.com/gp/product/149204637X">Amazon</a>, and is also free-to-use <a href="https://therinspark.com/">online</a>. We hope you find this book useful and easy to read.</p>
<p>To catch up on previous releases, take a look at the <a href="https://blog.rstudio.com/2019/03/15/sparklyr-1-0/">sparklyr 1.0</a> post or watch various video tutorials in the <a href="https://www.youtube.com/channel/UCAwJMtPx4HgmMXEDTvZBJ4A/playlists">mlverse</a> channel.</p>
<p>Thank you for reading along!</p>


<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
  tabsets.forEach(function(tabset) {
    const tabby = new Tabby('#' + tabset.id);
  });
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'light-border',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>



</body></html>